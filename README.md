## Sujit Mandava

MS in Artificial Intelligence, Northwestern University  
B.Tech in Computer Science, IIT Palakkad

I work on applied ML and AI systems where correctness, evaluation, and real-world constraints matter.  
I’m especially interested in LLM systems that need to operate reliably in production, where failure modes, data drift, and misuse are unavoidable rather than theoretical.

My work tends to sit between modeling and systems: building things that run, measuring where they break, and designing guardrails around them.

---

## Projects

**ShadowAI — Enterprise AI Usage Governance**  
Built a proxy-layer control plane to observe and enforce policy on LLM usage in enterprise settings. The system captures prompts, tool calls, and outputs to surface IP leakage risks, policy violations, and misuse patterns. Designed as an OpenAI-compatible gateway with minimal latency overhead, focusing on deployability rather than demos.  
Stack: Python, FastAPI, Docker, Nginx, cloud deployment.

**Staleness-Aware Retrieval-Augmented Generation**  
Developed a RAG system that explicitly tracks document freshness to reduce the impact of outdated information. The focus was less on improving static accuracy and more on understanding how retrieval systems degrade under temporal drift, and how to evaluate them when the ground truth itself changes.  
Stack: Python, vector databases, custom evaluation pipelines.

**Disinformation & Fairness Analysis**  
Trained and evaluated classifiers on globally imbalanced datasets, with an emphasis on regional performance disparities rather than aggregate metrics. This work focused on surfacing failure modes that are usually hidden by averaged benchmarks, especially in low-resource contexts.

---

## Technical Focus

I enjoy ideating and building quickly, especially when ideas can be tested end-to-end in working systems.  
I primarily use Python for ML and backend work, TypeScript or JavaScript for application logic and interfaces, and PostgreSQL for persistence.  
My ML interests include NLP, LLM systems, evaluation methodology, and fairness.  
On the systems side, I care about containerized services, cloud deployment, observability, and building things that are debuggable in production.  
I spend a lot of time on data pipelines, feature construction, and error analysis rather than model-only iteration.

---

## Experience

Software Engineer @ hGrid  
Delivery Data Engineer @ Turing  
Intern @ Arista Networks  

In addition to industry roles, much of my work has been research-driven or self-directed, usually motivated by gaps I noticed in how systems are evaluated or deployed.

---

## Contact

Email: sujitmandava123@gmail.com  
GitHub: https://github.com/sujitmandava  
LinkedIn: https://www.linkedin.com/in/sujit-mandava


## GitHub Activity


<p align = "right">
  <a href="https://github.com/sujitmandava">  
  <img src ="https://komarev.com/ghpvc/?username=sujitmandava&color=2266aa&style=flat" alt="Profile Visitors"/>
  </a>
</p>

<p align = "center">
  <a href="https://github.com/sujitmandava">
  <img src="https://github-profile-summary-cards.vercel.app/api/cards/profile-details?username=sujitmandava&theme=nord_dark" />
  </a>
  <br/>
  <br/>
  <a href="https://github.com/sujitmandava">
  <img src="https://github-profile-summary-cards.vercel.app/api/cards/repos-per-language?username=sujitmandava&theme=nord_dark" />
  </a>
  &nbsp;
  &nbsp;
  <a href="https://github.com/sujitmandava">
  <img src="https://github-profile-summary-cards.vercel.app/api/cards/most-commit-language?username=sujitmandava&theme=nord_dark" />
  </a>
</p>
